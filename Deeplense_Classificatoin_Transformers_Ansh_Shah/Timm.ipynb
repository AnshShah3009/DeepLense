{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.cct import CCT\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCT(\n",
    "    img_size=(224, 224),\n",
    "    embedding_dim=384,\n",
    "    n_conv_layers=3,\n",
    "    kernel_size=7,\n",
    "    stride=2,\n",
    "    padding=3,\n",
    "    pooling_kernel_size=5,\n",
    "    pooling_stride=2,\n",
    "    pooling_padding=1,\n",
    "    num_layers=14,\n",
    "    num_heads=6,\n",
    "    mlp_ratio=3.0,\n",
    "    num_classes=3,\n",
    "    n_input_channels=3,\n",
    "    positional_embedding=\"learnable\",  # ['sine', 'learnable', 'none']\n",
    ")\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'sphere', 'vort']\n",
      "['no', 'sphere', 'vort']\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "train_dataset = CustomDataset(\"/scratch/Ansh/DeepLense/specific_taskV/dataset/train\", transform=transform)\n",
    "test_dataset = CustomDataset(\"/scratch/Ansh/DeepLense/specific_taskV/dataset/val\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=300, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=300, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     epoch_loss = 0\n",
    "#     model.train()\n",
    "#     for data, label in tqdm(train_loader):\n",
    "#         output = model(data.to(device))\n",
    "#         loss = criterion(output, label.to(device))\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     model.eval()\n",
    "#     epoch_train = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, label in tqdm(test_loader):\n",
    "#             output = model(data.to(device))\n",
    "#             loss = criterion(output, label.to(device))\n",
    "#             epoch_train += loss.item()\n",
    "    \n",
    "#     print(f\"Epoch {epoch} Train Loss: {epoch_loss/len(train_loader)} Test Loss: {epoch_train/len(test_loader)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ansh_shah/.cache/torch/hub/pytorch_vision_v0.9.0\n",
      "/home/ansh_shah/miniconda3/envs/devapi/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ansh_shah/miniconda3/envs/devapi/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = torch.hub.load(\"pytorch/vision:v0.9.0\", \"resnet18\", pretrained=False)\n",
    "\n",
    "resnet.fc = torch.nn.Linear(512, 3)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:18<01:08,  1.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 19\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(label)\n\u001b[1;32m     22\u001b[0m resnet\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "file = open(\"resnet18.txt\", \"w\")\n",
    "\n",
    "for epoch in range(3000):\n",
    "    epoch_loss = 0\n",
    "    accuracy = 0\n",
    "    resnet.train()\n",
    "    for data, label in tqdm(train_loader):\n",
    "        output = resnet(data.to(device))\n",
    "        loss = criterion(output, label.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        accuracy += (output.argmax(1) == label.to(device)).sum().item() / len(label)\n",
    "\n",
    "    resnet.eval()\n",
    "    epoch_train = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in tqdm(test_loader):\n",
    "            output = resnet(data.to(device))\n",
    "            loss = criterion(output, label.to(device))\n",
    "            epoch_train += loss.item()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch} Train Loss: {epoch_loss/len(train_loader)} Test Loss: {epoch_train/len(test_loader), accuracy/len(train_loader)}\"\n",
    "    )\n",
    "\n",
    "    file.write(\n",
    "        f\"Epoch {epoch} Train Loss: {epoch_loss/len(train_loader)} Test Loss: {epoch_train/len(test_loader), accuracy/len(train_loader)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
